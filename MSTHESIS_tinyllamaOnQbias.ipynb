{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyN9YM3GS2hsQSz7wPcCN4Q2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SodiKroehler/MSTHESIS/blob/main/MSTHESIS_tinyllamaOnQbias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# from langdetect import detect\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "8ILS7PJ41Gec",
        "outputId": "eae41d29-0dee-4251-fbf2-32ee9e87d97d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdf = pd.read_csv(\"/content/week4_cleaned.csv\")\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "rdf = rdf[rdf['repeatType'] == 'subtitle']\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", device_map=\"auto\")\n"
      ],
      "metadata": {
        "id": "lM2FohYt1qX_",
        "outputId": "3c4b05f8-0892-49fd-8c40-cdb7ded0805e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'preprocessing' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d3f2a08ac145>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/week4_cleaned.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repeatType'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'subtitle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocessing' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LlamaMultiClassClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_classes):\n",
        "        super(LlamaMultiClassClassifier, self).__init__()\n",
        "        self.llama = AutoModel.from_pretrained(model_name)\n",
        "        self.classifier = nn.Linear(self.llama.config.hidden_size, num_classes)  # Single classifier head\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.llama(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state[:, 0, :]  # Take [CLS] token embedding\n",
        "        logits = self.classifier(hidden_states)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "TofrgIAc1PWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", device_map=\"auto\")\n",
        "\n",
        "class MultiClassDataset(Dataset):\n",
        "    def __init__(self, queries, labels, tokenizer, max_length=256):\n",
        "        self.queries = queries\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.queries)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.queries[idx]\n",
        "        inputs = self.tokenizer(text, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": self.labels[idx]\n",
        "        }\n",
        "\n",
        "# Create dataset & dataloader\n",
        "dataset = MultiClassDataset(ldf[\"user_query\"].tolist(), labels, tokenizer)\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "uBrNCCin1Q25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_encoder = LabelEncoder()\n",
        "ldf[\"class_id\"] = label_encoder.fit_transform(ldf[\"code\"])\n",
        "\n",
        "labels = torch.tensor(ldf[\"class_id\"].values, dtype=torch.long)\n",
        "\n",
        "label_mapping = {idx: label for idx, label in enumerate(label_encoder.classes_)}\n",
        "\n",
        "\n",
        "dataset = MultiClassDataset(rdf[\"clean\"].tolist(), labels, tokenizer)\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "labels = torch.tensor(ldf[\"class_id\"].values, dtype=torch.long)\n",
        "\n",
        "label_mapping = {idx: label for idx, label in enumerate(label_encoder.classes_)}"
      ],
      "metadata": {
        "id": "OFpjorM02P8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "3gdir-sn1TWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LlamaMultiClassClassifier(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}\")\n"
      ],
      "metadata": {
        "id": "UZOq1TGW1UuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Create save directory\n",
        "save_dir = \"tinyllama_classification_model\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), os.path.join(save_dir, \"model.pth\"))\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "# Save label encoder (if needed)\n",
        "import pickle\n",
        "with open(os.path.join(save_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MPNMX-Ky1Wjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, label_encoder):\n",
        "    model.eval()\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].cpu().numpy()  # Ground truth labels\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            predictions = torch.argmax(logits, dim=1).cpu().numpy()  # Convert to predicted class index\n",
        "\n",
        "            true_labels.extend(labels)\n",
        "            pred_labels.extend(predictions)\n",
        "\n",
        "    # Convert class IDs back to labels\n",
        "    true_labels = label_encoder.inverse_transform(true_labels)\n",
        "    pred_labels = label_encoder.inverse_transform(pred_labels)\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(true_labels, pred_labels))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SB49AOvI1alG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}