{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffe880c8-f029-4066-b0a5-42ca612bf336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88b7219-d1e8-44b4-8317-7716ca6d58ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972aa373e156451093cd48df853bc8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The quick brown fox jumps over the lazy dog.\n",
      "Average Log Probability: -1.6318\n",
      "Per-token Log Probs: [-10.1328, -8.3281, -0.0698, -0.0097, -0.002, -0.0336, -0.001, -0.027, -0.0308, -0.0165, -0.0222, -0.9102]\n"
     ]
    }
   ],
   "source": [
    "#testing one off\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,  # or bfloat16 or int8/int4 if quantized\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "shift_logits = logits[:, :-1, :]\n",
    "shift_labels = input_ids[:, 1:]\n",
    "log_probs = torch.nn.functional.log_softmax(shift_logits, dim=-1)\n",
    "token_log_probs = log_probs.gather(2, shift_labels.unsqueeze(-1)).squeeze(-1)\n",
    "average_log_prob = token_log_probs.mean().item()\n",
    "print(f\"Input: {input_text}\")\n",
    "print(f\"Average Log Probability: {average_log_prob:.4f}\")\n",
    "print(f\"Per-token Log Probs: {[round(lp.item(), 4) for lp in token_log_probs[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6c48ee3-d69c-48ac-92e2-798db7acd2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /ihome/xli/sek188/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#data sources\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "full_df = pd.read_csv(\"procon_longer.csv\")\n",
    "irdf = pd.read_csv(\"interpretive_repertoires.csv\")\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "full_df['raw_text'] = full_df['point'] + \"\\n\" + full_df['explanation']\n",
    "full_df[\"clean\"] = full_df[\"raw_text\"].apply(clean_text)\n",
    "\n",
    "# full_df.head()\n",
    "fdf = full_df[['title', 'stance', 'clean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5af8da60-dbc8-4a98-8d4e-674debe6d88f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>stance</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Filibuster</td>\n",
       "      <td>pro</td>\n",
       "      <td>pro 1: filibuster promotes compromise protects...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filibuster</td>\n",
       "      <td>pro</td>\n",
       "      <td>pro 2: filibuster protects intended purpose se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Filibuster</td>\n",
       "      <td>pro</td>\n",
       "      <td>pro 3: filibuster important safeguard politica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filibuster</td>\n",
       "      <td>con</td>\n",
       "      <td>con 1: filibuster promotes obstructionism part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filibuster</td>\n",
       "      <td>con</td>\n",
       "      <td>con 2: filibuster prevents meaningful debate s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        title stance                                              clean\n",
       "0  Filibuster    pro  pro 1: filibuster promotes compromise protects...\n",
       "1  Filibuster    pro  pro 2: filibuster protects intended purpose se...\n",
       "2  Filibuster    pro  pro 3: filibuster important safeguard politica...\n",
       "3  Filibuster    con  con 1: filibuster promotes obstructionism part...\n",
       "4  Filibuster    con  con 2: filibuster prevents meaningful debate s..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a1f1b63-75f8-4ebf-9c5c-8bd07fecf44b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#stitching and liloing\n",
    "combined_rows = []\n",
    "for _, f_row in fdf.iterrows():\n",
    "    for _, ir_row in irdf.iterrows():\n",
    "        combined_row = {\n",
    "            **f_row.to_dict(),      # all columns from fdf\n",
    "            **ir_row.to_dict()      # all columns from irdf\n",
    "        }\n",
    "        combined_rows.append(combined_row)\n",
    "\n",
    "cdf = pd.DataFrame(combined_rows)\n",
    "cdf[\"attestation\"] = cdf[\"likes\"].combine_first(cdf[\"dislikes\"])\n",
    "cdf[\"input_text\"] = cdf[\"attestation\"] + \"\\n\\n\" + cdf[\"clean\"]\n",
    "cdf.drop(columns=['likes', 'dislikes', 'guidewords'])\n",
    "\n",
    "funkyoutputblocker = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0dde4da4-d727-4001-88f1-deaee39ac28f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9758/9758 [21:50:44<00:00,  8.06s/it]   \n"
     ]
    }
   ],
   "source": [
    "#temp to test:\n",
    "# cdf = cdf.head()\n",
    "\n",
    "#model bit\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# Compute logprobs\n",
    "logprobs = []\n",
    "for idx, row in tqdm(cdf.iterrows(), total=len(cdf)):\n",
    "    inputs = tokenizer(row['input_text'], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    shift_logits = logits[:, :-1, :]\n",
    "    shift_labels = input_ids[:, 1:]\n",
    "    log_probs = torch.nn.functional.log_softmax(shift_logits, dim=-1)\n",
    "    token_log_probs = log_probs.gather(2, shift_labels.unsqueeze(-1)).squeeze(-1)\n",
    "    average_log_prob = token_log_probs.mean().item()\n",
    "    logprobs.append(average_log_prob)\n",
    "\n",
    "cdf[\"logprob\"] = logprobs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f147fb1c-1912-4c27-bb41-72715df6217a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.mean of 0      -3.229038\n",
       "1      -3.173262\n",
       "2      -3.139151\n",
       "3      -3.127598\n",
       "4      -3.019099\n",
       "          ...   \n",
       "9753   -3.156641\n",
       "9754   -3.308724\n",
       "9755   -3.100954\n",
       "9756   -3.126193\n",
       "9757   -3.292845\n",
       "Name: logprob, Length: 9758, dtype: float64>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.to_csv('procon_coh_long.csv')\n",
    "cdf['logprob'].mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
