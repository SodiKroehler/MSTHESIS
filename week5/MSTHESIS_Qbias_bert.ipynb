{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf7811d-fe53-4b96-a7b0-62c3af736e74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate==1.4.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.4.6 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 2)) (2.4.6)\n",
      "Requirement already satisfied: aiohttp==3.11.12 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 3)) (3.11.12)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: alembic==1.14.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 5)) (1.14.1)\n",
      "Requirement already satisfied: attrs==25.1.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 6)) (25.1.0)\n",
      "Requirement already satisfied: banal==1.0.6 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 7)) (1.0.6)\n",
      "Requirement already satisfied: certifi==2025.1.31 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 8)) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 9)) (3.4.1)\n",
      "Requirement already satisfied: dataset==1.6.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 10)) (1.6.2)\n",
      "Requirement already satisfied: datasets==3.3.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 11)) (3.3.2)\n",
      "Requirement already satisfied: dill==0.3.8 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 12)) (0.3.8)\n",
      "Requirement already satisfied: filelock==3.17.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 13)) (3.17.0)\n",
      "Requirement already satisfied: frozenlist==1.5.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: fsspec==2024.12.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 15)) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub==0.28.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 16)) (0.28.1)\n",
      "Requirement already satisfied: idna==3.10 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 17)) (3.10)\n",
      "Requirement already satisfied: Jinja2==3.1.5 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 18)) (3.1.5)\n",
      "Requirement already satisfied: joblib==1.4.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 19)) (1.4.2)\n",
      "Requirement already satisfied: Mako==1.3.9 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 20)) (1.3.9)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 21)) (3.0.2)\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 22)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.1.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 23)) (6.1.0)\n",
      "Requirement already satisfied: multiprocess==0.70.16 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 24)) (0.70.16)\n",
      "Requirement already satisfied: networkx==3.4.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 25)) (3.4.2)\n",
      "Requirement already satisfied: numpy==2.2.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 26)) (2.2.2)\n",
      "Requirement already satisfied: packaging==24.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 27)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 28)) (2.2.3)\n",
      "Requirement already satisfied: propcache==0.3.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 29)) (0.3.0)\n",
      "Requirement already satisfied: psutil==7.0.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 30)) (7.0.0)\n",
      "Requirement already satisfied: pyarrow==19.0.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 31)) (19.0.1)\n",
      "Requirement already satisfied: pyreadstat==1.2.8 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 32)) (1.2.8)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 33)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 34)) (2024.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 35)) (6.0.2)\n",
      "Requirement already satisfied: regex==2024.11.6 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 36)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 37)) (2.32.3)\n",
      "Requirement already satisfied: safetensors==0.5.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 38)) (0.5.2)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 39)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 40)) (1.15.1)\n",
      "Requirement already satisfied: setuptools==75.8.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 41)) (75.8.0)\n",
      "Requirement already satisfied: six==1.17.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 42)) (1.17.0)\n",
      "Requirement already satisfied: SQLAlchemy==1.4.54 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 43)) (1.4.54)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 44)) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 45)) (3.5.0)\n",
      "Requirement already satisfied: tokenizers==0.21.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 46)) (0.21.0)\n",
      "Requirement already satisfied: torch==2.6.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 47)) (2.6.0)\n",
      "Requirement already satisfied: tqdm==4.67.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 48)) (4.67.1)\n",
      "Requirement already satisfied: transformers==4.48.3 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 49)) (4.48.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 50)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2025.1 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 51)) (2025.1)\n",
      "Requirement already satisfied: urllib3==2.3.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 52)) (2.3.0)\n",
      "Requirement already satisfied: xxhash==3.5.0 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 53)) (3.5.0)\n",
      "Requirement already satisfied: yarl==1.18.3 in ./.local/lib/python3.10/site-packages (from -r MSTHESIS/week5/requirements.txt (line 54)) (1.18.3)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp==3.11.12->-r MSTHESIS/week5/requirements.txt (line 3)) (5.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.local/lib/python3.10/site-packages (from SQLAlchemy==1.4.54->-r MSTHESIS/week5/requirements.txt (line 43)) (3.1.1)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.10/site-packages (from torch==2.6.0->-r MSTHESIS/week5/requirements.txt (line 47)) (12.3.1.170)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r MSTHESIS/week5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd85193-5b34-45b8-b74d-585c8fbb97b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from collections import Counter\n",
    "import time\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e1416a4-33af-4765-92f8-fd63164a6c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "SAMPLE_SIZE = 3000\n",
    "BATCH_SIZE = 32\n",
    "# os.chdir('./MSTHESIS/week5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9711d4-b49b-43b5-b41d-38a44591aa8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_anything(rdf, modelName, uncased=True, num_classes=2, label_col='label'):\n",
    "    start_time = time.time()\n",
    "    directory_path = \"./models/\"+modelName\n",
    "\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    rdf['label'] = label_encoder.fit_transform(rdf[label_col].tolist())\n",
    "    print(rdf['label'].value_counts())\n",
    "    \n",
    "    train_df, test_df = train_test_split(rdf, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "    CASEMENT_NAME = \"distilbert-base-uncased\" if uncased else \"distilbert-base-cased\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CASEMENT_NAME)\n",
    "        \n",
    "\n",
    "    def tokenize_data(examples):\n",
    "        return tokenizer(examples[\"raw\"] if not uncased else examples[\"clean\"], truncation=True)\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "    \n",
    "    tokenized_train = train_dataset.map(tokenize_data, batched=True)\n",
    "    tokenized_test = test_dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CASEMENT_NAME, num_labels=num_classes)\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=directory_path+\"/results\",\n",
    "        learning_rate=2e-4,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        # load_best_model_at_end=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model(directory_path+\"/model\")\n",
    "\n",
    "    #prediction\n",
    "\n",
    "    predictions = trainer.predict(tokenized_test)\n",
    "\n",
    "    logits = predictions.predictions \n",
    "    predicted_labels = np.argmax(logits, axis=1) \n",
    "    true_labels = test_df['label'].values\n",
    "\n",
    "    # Step 3: Compute Metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average=\"weighted\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return [modelName, accuracy, precision, recall, f1, start_time, (start_time-end_time), end_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab9139d0-2495-4903-81c2-2f2b5f11bd79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_all_combos():\n",
    "    rdf = pd.read_csv(\"week5_qbias_dataset.csv\")\n",
    "    if not os.path.exists(\"week5_results.csv\"):\n",
    "        resPD = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Start_Time\", \"Duration\", \"End_Date\"])\n",
    "    else:\n",
    "        resPD = pd.read_csv(\"week5_results.csv\")\n",
    "    results = []\n",
    "    rdf.dropna(subset=['clean'], inplace=True)\n",
    "    rdf = rdf[rdf['clean'].str.len() > 0]\n",
    "    \n",
    "    MODEL_SIZE = \"small\"\n",
    "    if MODEL_SIZE == \"small\":\n",
    "        rdf = rdf.sample(SAMPLE_SIZE, random_state=RANDOM_SEED)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for uncased in [True, False]:\n",
    "#         results.append(train_anything(rdf, f\"{MODEL_SIZE}_multiclass_{'uncased' if uncased else 'cased'}\", uncased, 3, 'bias_rating'))\n",
    "    \n",
    "    # for uncased in [True, False]:\n",
    "    #     results.append(train_anything(rdf, f\"{MODEL_SIZE}_binary_left{'' if uncased else '_cased'}\", uncased, 2, 'label_left'))\n",
    "\n",
    "    #not left\n",
    "#     rdf['label_not_left'] = rdf['label_left'].apply(lambda x: 0 if x == 1 else 1)\n",
    "#     results.append(train_anything(rdf, f\"{MODEL_SIZE}_binary_not_left\", False, 2, 'label_not_left'))\n",
    "    \n",
    "    #right \n",
    "    results.append(train_anything(rdf, f\"{MODEL_SIZE}_binary_right\", False, 2, 'label_right'))\n",
    "\n",
    "    #center\n",
    "    results.append(train_anything(rdf, f\"{MODEL_SIZE}_binary_center\", False, 2, 'label_center'))\n",
    "    \n",
    "    #evenly sampled left\n",
    "    rdf = pd.read_csv(\"week5_qbias_dataset.csv\")\n",
    "    rdf_yes = rdf[rdf['label_left'] > 0]\n",
    "    rdf_no = rdf[rdf['label_left'] == 0]\n",
    "    rdf_yes_resampled = resample(rdf_yes, \n",
    "                               replace=False, \n",
    "                               n_samples=SAMPLE_SIZE,\n",
    "                               random_state=RANDOM_SEED)\n",
    "        \n",
    "    \n",
    "    if MODEL_SIZE == \"small\": \n",
    "        rdf_no_resampled = resample(rdf_no, \n",
    "                                   replace=False, \n",
    "                                   n_samples=SAMPLE_SIZE,\n",
    "                                   random_state=RANDOM_SEED)\n",
    "        rdf_even_sample_left = pd.concat([rdf_yes_resampled, rdf_no_resampled], ignore_index = True)\n",
    "    else:\n",
    "        rdf_no_resampled = resample(rdf_no, \n",
    "                                       replace=False, \n",
    "                                       n_samples=rdf_yes.shape[0],\n",
    "                                       random_state=RANDOM_SEED)\n",
    "        rdf_even_sample_left = pd.concat([rdf_yes, rdf_no_resampled], ignore_index = True)\n",
    "\n",
    "\n",
    "    results.append(train_anything(rdf_even_sample_left, f\"{MODEL_SIZE}_binary_evenSplit_left\", False, 2, 'label_left'))\n",
    "    \n",
    "    \n",
    "\n",
    "    newresPd = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Start_Time\", \"Duration\", \"End_Date\"])\n",
    "    pdResults = pd.concat([resPD, newresPd], ignore_index=True)\n",
    "    pdResults.to_csv(\"week5_results.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e745c327-fd12-4b3b-a00a-4847b1974c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_anything(rdf, modelName, labelColumn='bias_rating'):\n",
    "    model_path = \"./models/\"+modelName+\"/model\"   \n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    rdf['label'] = label_encoder.fit_transform(rdf[labelColumn].tolist())\n",
    "    rdf.dropna(subset=['clean'], inplace=True)\n",
    "    headlines = rdf[\"clean\"].tolist()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    batch_size = 32 \n",
    "    def tokenize_batch(batch_texts):\n",
    "        return tokenizer(batch_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(headlines), batch_size), desc=\"Processing Batches\"):\n",
    "            batch_texts = headlines[i:i+batch_size]  # Get batch\n",
    "            batch_inputs = tokenize_batch(batch_texts).to(device)  # Tokenize and move to GPU\n",
    "\n",
    "            outputs = model(**batch_inputs)\n",
    "            batch_predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "            all_predictions.extend(batch_predictions)\n",
    "    \n",
    "    # Convert back to original bias categories\n",
    "    decoded_labels = label_encoder.inverse_transform(all_predictions)\n",
    "\n",
    "    true_labels = rdf['label'].values  # True labels\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, all_predictions, average=\"weighted\")\n",
    "\n",
    "    return [modelName, accuracy, precision, recall, f1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c61e3521-3059-435a-aec3-a16f6974d168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def eval_all_combos():\n",
    "    rdf = pd.read_csv(\"week5_qbias_dataset.csv\")\n",
    "    if not os.path.exists(\"week5_evals.csv\"):\n",
    "        resPD = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"EvalDate\"])\n",
    "    else:\n",
    "        resPD = pd.read_csv(\"week5_results.csv\")\n",
    "    results = []\n",
    "    train_df, test_df = train_test_split(rdf, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    rdf = test_df\n",
    "    rdf.dropna(subset=['clean'], inplace=True)\n",
    "    rdf = rdf[rdf['clean'].str.len() > 0]\n",
    "    \n",
    "    \n",
    "    # rdf = rdf.sample(SAMPLE_SIZE, random_state=RANDOM_SEED+5)\n",
    "    \n",
    "    MODEL_SIZE = \"\"\n",
    "    # for uncased in [True, False]:\n",
    "        # results.append(eval_anything(rdf, f\"{MODEL_SIZE}_multiclass_{'uncased' if uncased else 'cased'}\", 'bias_rating'))\n",
    "    results.append(eval_anything(rdf, \"multiclass_uncased\", 'bias_rating'))\n",
    "    results.append(eval_anything(rdf, \"multiclass_left\", 'label_left'))\n",
    "    \n",
    "#     for uncased in [True, False]:\n",
    "#         results.append(eval_anything(rdf, f\"{MODEL_SIZE}_binary_left{'' if uncased else '_cased'}\", 'label_left'))\n",
    "\n",
    "#     #not left\n",
    "#     rdf['label_not_left'] = rdf['label_left'].apply(lambda x: 0 if x == 1 else 1)\n",
    "#     results.append(eval_anything(rdf, f\"{MODEL_SIZE}_binary_not_left\", 'label_not_left'))\n",
    "    \n",
    "#     #right \n",
    "#     results.append(eval_anything(rdf, f\"{MODEL_SIZE}_binary_right\", 'label_right'))\n",
    "\n",
    "#     #center\n",
    "#     results.append(eval_anything(rdf, f\"{MODEL_SIZE}_binary_center\", 'label_center'))\n",
    "    \n",
    "    #evenly sampled center\n",
    "    rdf = pd.read_csv(\"week5_qbias_dataset.csv\")\n",
    "    rdf_yes = rdf[rdf['label_left'] > 0]\n",
    "    rdf_no = rdf[rdf['label_left'] == 0]\n",
    "\n",
    "    rdf_no_resampled = resample(rdf_no, \n",
    "                                   replace=False, \n",
    "                                   n_samples=SAMPLE_SIZE,\n",
    "                                   random_state=RANDOM_SEED)\n",
    "    rdf_yes_resampled = resample(rdf_yes, \n",
    "                                   replace=False, \n",
    "                                   n_samples=SAMPLE_SIZE,\n",
    "                                   random_state=RANDOM_SEED)\n",
    "    \n",
    "    rdf_even_sample_left = pd.concat([rdf_yes_resampled, rdf_no_resampled], ignore_index = True)\n",
    "\n",
    "    # rdf_no_resampled = resample(rdf_no, \n",
    "    #                                replace=False, \n",
    "    #                                n_samples=rdf_yes.shape[0],\n",
    "    #                                random_state=RANDOM_SEED)\n",
    "    \n",
    "    # rdf_even_sample_left = pd.concat([rdf_yes, rdf_no_resampled], ignore_index = True)\n",
    "\n",
    "    results.append(eval_anything(rdf_even_sample_left, \"binary_evenSplit_left\", 'label_left'))\n",
    "    \n",
    "    \n",
    "    newresPd = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "    newresPD[\"EvalDate\"] =  datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    pdResults = pd.concat([resPD, newresPd], ignore_index=True)\n",
    "    pdResults.to_csv(\"week5_evals2.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "33f61e56-3a12-420f-957d-c1ffb0222106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 63/63 [03:15<00:00,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6715, Precision: 0.4509, Recall: 0.6715, F1: 0.5395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/ihome/xli/sek188/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdf = pd.read_csv(\"week5_qbias_dataset.csv\")\n",
    "rdf = rdf.sample(2000, random_state=RANDOM_SEED)\n",
    "model_path = \"./models/binary_right/model\"   \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "rdf['label'] = label_encoder.fit_transform(rdf['label_right'].tolist())\n",
    "rdf.dropna(subset=['clean'], inplace=True)\n",
    "headlines = rdf['clean'].tolist()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 32\n",
    "def tokenize_batch(batch_texts):\n",
    "    return tokenizer(batch_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(headlines), batch_size), desc=\"Processing Batches\"):\n",
    "        batch_texts = headlines[i:i+batch_size]\n",
    "        batch_inputs = tokenize_batch(batch_texts).to(device)\n",
    "        \n",
    "        outputs = model(**batch_inputs)\n",
    "        batch_predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(batch_predictions)\n",
    "\n",
    "# Convert back to original bias categories\n",
    "decoded_labels = label_encoder.inverse_transform(all_predictions)\n",
    "\n",
    "# Compute metrics\n",
    "true_labels = rdf['label'].values\n",
    "accuracy = accuracy_score(true_labels, all_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, all_predictions, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34e074eb-2d63-4c18-bdf0-0ea6d0ecf432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    1343\n",
      "1     657\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# decoded_labels\n",
    "# true_labels\n",
    "# all_predictions\n",
    "# accuracy\n",
    "# print(rdf['label'].value_counts())\n",
    "# # print(rdf[['label_center', 'label']].head())\n",
    "\n",
    "\n",
    "recall_df = pd.DataFrame({\n",
    "    \"text\": rdf[\"clean\"].tolist(),  # Original text\n",
    "    \"true_label\": rdf[\"label\"].values,  # True labels\n",
    "    \"predicted_label\": all_predictions  # Model predictions\n",
    "})\n",
    "\n",
    "# recall_df[(recall_df[\"true_label\"] == 0) & (recall_df[\"predicted_label\"] == 0)].shape\n",
    "# # ['text'][0]\n",
    "# recall_df['true_label'].value_counts()\n",
    "# confusion_matrix = metrics.confusion_matrix(true_labels, all_predictions)\n",
    "# confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbe7b67b-78c7-4c46-be1d-bac9f89e26ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>bias_rating</th>\n",
       "      <th>clean</th>\n",
       "      <th>label_right</th>\n",
       "      <th>label_left</th>\n",
       "      <th>label_center</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>[HEADLINE]Derek Chauvin trial and George Floyd...</td>\n",
       "      <td>left</td>\n",
       "      <td>[headline]derek chauvin trial and george floyd...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>[HEADLINE]Democratic platform focuses on fixin...</td>\n",
       "      <td>right</td>\n",
       "      <td>[headline]democratic platform focuses on fixin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>[HEADLINE]Omicron-specific vaccine boosters ge...</td>\n",
       "      <td>left</td>\n",
       "      <td>[headline]omicron-specific vaccine boosters ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20210</th>\n",
       "      <td>[HEADLINE]Annoying to the End — Jeff Flake Pub...</td>\n",
       "      <td>right</td>\n",
       "      <td>[headline]annoying to the end — jeff flake pub...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>[HEADLINE]Oklahoma's new abortion law doesn't ...</td>\n",
       "      <td>center</td>\n",
       "      <td>[headline]oklahoma's new abortion law doesn't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     raw bias_rating  \\\n",
       "13167  [HEADLINE]Derek Chauvin trial and George Floyd...        left   \n",
       "4068   [HEADLINE]Democratic platform focuses on fixin...       right   \n",
       "9857   [HEADLINE]Omicron-specific vaccine boosters ge...        left   \n",
       "20210  [HEADLINE]Annoying to the End — Jeff Flake Pub...       right   \n",
       "7655   [HEADLINE]Oklahoma's new abortion law doesn't ...      center   \n",
       "\n",
       "                                                   clean  label_right  \\\n",
       "13167  [headline]derek chauvin trial and george floyd...            0   \n",
       "4068   [headline]democratic platform focuses on fixin...            1   \n",
       "9857   [headline]omicron-specific vaccine boosters ge...            0   \n",
       "20210  [headline]annoying to the end — jeff flake pub...            1   \n",
       "7655   [headline]oklahoma's new abortion law doesn't ...            0   \n",
       "\n",
       "       label_left  label_center  label  \n",
       "13167           1             0      0  \n",
       "4068            0             0      1  \n",
       "9857            1             0      0  \n",
       "20210           0             0      1  \n",
       "7655            0             1      0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall_df.head()\n",
    "# recall_df.iloc[4,0]\n",
    "\n",
    "# srdf = rdf.sample(SAMPLE_SIZE, random_state=RANDOM_SEED)\n",
    "rdf.head()\n",
    "# rdf.iloc[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c63d186-f962-49b2-ab34-8dc3ff6a7e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "def predict_single(text, model, tokenizer, label_encoder, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Run the model to get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Convert logits to predicted label\n",
    "    predicted_label = torch.argmax(outputs.logits, dim=-1).cpu().numpy()[0]\n",
    "    \n",
    "    # Convert back to original label categories\n",
    "    decoded_label = label_encoder.inverse_transform([predicted_label])[0]\n",
    "    \n",
    "    return decoded_label\n",
    "\n",
    "# Example usage\n",
    "text = rdf.iloc[3,2]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "prediction = predict_single(text, model, tokenizer, label_encoder, device)\n",
    "\n",
    "print(f\"Predicted label: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc5468-3712-4c55-9369-4e2b673a62d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_all_combos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "679d75bc-5988-40c8-ad46-02d8b7d3fd18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/136 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Processing Batches:   0%|          | 0/136 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_all_combos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 19\u001b[0m, in \u001b[0;36meval_all_combos\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     MODEL_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# for uncased in [True, False]:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# results.append(eval_anything(rdf, f\"{MODEL_SIZE}_multiclass_{'uncased' if uncased else 'cased'}\", 'bias_rating'))\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43meval_anything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulticlass_uncased\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(eval_anything(rdf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass_left\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_left\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     for uncased in [True, False]:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         results.append(eval_anything(rdf, f\"{MODEL_SIZE}_binary_left{'' if uncased else '_cased'}\", 'label_left'))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#evenly sampled center\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m, in \u001b[0;36meval_anything\u001b[0;34m(rdf, modelName, labelColumn)\u001b[0m\n\u001b[1;32m     24\u001b[0m batch_texts \u001b[38;5;241m=\u001b[39m headlines[i:i\u001b[38;5;241m+\u001b[39mbatch_size]  \u001b[38;5;66;03m# Get batch\u001b[39;00m\n\u001b[1;32m     25\u001b[0m batch_inputs \u001b[38;5;241m=\u001b[39m tokenize_batch(batch_texts)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Tokenize and move to GPU\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m batch_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     30\u001b[0m all_predictions\u001b[38;5;241m.\u001b[39mextend(batch_predictions)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:977\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    975\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 977\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    987\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:784\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    782\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 784\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[1;32m    787\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:116\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[0;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03membeddings)\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     input_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m input_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# isues similar to issue #5664\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "eval_all_combos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74d85f38-466a-435b-b6d7-62b2e443cd75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>End_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multiclass_uncased</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741472e+09</td>\n",
       "      <td>-34.023830</td>\n",
       "      <td>2025-03-08 17:11:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multiclass_cased</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741472e+09</td>\n",
       "      <td>-32.221397</td>\n",
       "      <td>2025-03-08 17:11:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>binary_left</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741472e+09</td>\n",
       "      <td>-31.957928</td>\n",
       "      <td>2025-03-08 17:12:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>binary_left_cased</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741472e+09</td>\n",
       "      <td>-31.746595</td>\n",
       "      <td>2025-03-08 17:12:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>binary_not_left</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741472e+09</td>\n",
       "      <td>-31.091362</td>\n",
       "      <td>2025-03-08 17:13:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>binary_right</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741472e+09</td>\n",
       "      <td>-31.184011</td>\n",
       "      <td>2025-03-08 17:13:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>binary_center</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741472e+09</td>\n",
       "      <td>-32.180439</td>\n",
       "      <td>2025-03-08 17:14:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>binary_evenSplit_left</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.741472e+09</td>\n",
       "      <td>-52.050959</td>\n",
       "      <td>2025-03-08 17:15:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multiclass_uncased</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741476e+09</td>\n",
       "      <td>-34.511598</td>\n",
       "      <td>2025-03-08 18:16:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>multiclass_cased</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.741476e+09</td>\n",
       "      <td>-35.182627</td>\n",
       "      <td>2025-03-08 18:16:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Accuracy  Precision  Recall        F1    Start_Time  \\\n",
       "0     multiclass_uncased      1.00     1.0000    1.00  1.000000  1.741472e+09   \n",
       "1       multiclass_cased      1.00     1.0000    1.00  1.000000  1.741472e+09   \n",
       "2            binary_left      1.00     1.0000    1.00  1.000000  1.741472e+09   \n",
       "3      binary_left_cased      1.00     1.0000    1.00  1.000000  1.741472e+09   \n",
       "4        binary_not_left      1.00     1.0000    1.00  1.000000  1.741472e+09   \n",
       "5           binary_right      1.00     1.0000    1.00  1.000000  1.741472e+09   \n",
       "6          binary_center      1.00     1.0000    1.00  1.000000  1.741472e+09   \n",
       "7  binary_evenSplit_left      0.75     0.5625    0.75  0.642857  1.741472e+09   \n",
       "8     multiclass_uncased      1.00     1.0000    1.00  1.000000  1.741476e+09   \n",
       "9       multiclass_cased      1.00     1.0000    1.00  1.000000  1.741476e+09   \n",
       "\n",
       "    Duration             End_Date  \n",
       "0 -34.023830  2025-03-08 17:11:03  \n",
       "1 -32.221397  2025-03-08 17:11:35  \n",
       "2 -31.957928  2025-03-08 17:12:07  \n",
       "3 -31.746595  2025-03-08 17:12:39  \n",
       "4 -31.091362  2025-03-08 17:13:10  \n",
       "5 -31.184011  2025-03-08 17:13:41  \n",
       "6 -32.180439  2025-03-08 17:14:13  \n",
       "7 -52.050959  2025-03-08 17:15:06  \n",
       "8 -34.511598  2025-03-08 18:16:09  \n",
       "9 -35.182627  2025-03-08 18:16:44  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"week5_results.csv\")\n",
    "results.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
